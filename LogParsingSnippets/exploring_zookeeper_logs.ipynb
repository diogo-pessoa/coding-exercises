{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-05T14:33:43.297157Z",
     "start_time": "2026-02-05T14:33:43.293667Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T18:12:59.094407Z",
     "start_time": "2026-02-05T18:12:59.075668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "class LogProcessor:\n",
    "    def __init__(self):\n",
    "        self.log_level_counters = {}\n",
    "        self.total_lines_processed = 0\n",
    "        self.parse_failed = 0\n",
    "        self.loggers = {}\n",
    "\n",
    "        # keep contract explicit\n",
    "        self.valid_levels = {\"INFO\", \"WARN\", \"ERROR\"}\n",
    "\n",
    "    def inspect_log_file(self, file_path: str):\n",
    "        if not os.path.exists(file_path):  # fail early file not found\n",
    "            raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as zk_logs:\n",
    "                for raw_line in zk_logs:\n",
    "                    line = raw_line.strip()\n",
    "\n",
    "                    if not line:\n",
    "                        self.parse_failed += 1\n",
    "                        continue\n",
    "\n",
    "                    # Keep your approach: split once on \" - \"\n",
    "                    event = line.split(\" - \", 2)\n",
    "\n",
    "                    if len(event) >= 2:\n",
    "                        # event[1] is like: \"WARN  [QuorumPeer...]\" (level + bracket section)\n",
    "                        level_token = event[1].split()[0] if event[1].split() else \"UNKNOWN\"\n",
    "                        level = level_token if level_token in self.valid_levels else \"UNKNOWN\"\n",
    "\n",
    "                        self._increment_log_level_counter(level)  # LogLevel counting\n",
    "\n",
    "                        # IMPORTANT FIX:\n",
    "                        # previously doing: event[1].split()[1]\n",
    "                        # That isn't reliable. Extract logger/source from the actual bracket content in the full line.\n",
    "                        raw_logger = self._extract_bracket_content(line)  # e.g. \"QuorumPeer[myid=1](plain=...)...\"\n",
    "                        self._count_loggers(raw_logger)\n",
    "\n",
    "                    else:\n",
    "                        # malformed line (can't split into expected segments)\n",
    "                        self._increment_log_level_counter(\"UNKNOWN\")\n",
    "                        self._count_loggers(\"\")  # count as UNKNOWN_SOURCE\n",
    "\n",
    "                    self.total_lines_processed += 1\n",
    "\n",
    "                return self.get_file_report()\n",
    "\n",
    "        except OSError as err:\n",
    "            print(f\"Failed to inspect file: {err}\")\n",
    "            raise\n",
    "\n",
    "    def _increment_log_level_counter(self, log_level: str):\n",
    "        self.log_level_counters[log_level] = self.log_level_counters.get(log_level, 0) + 1\n",
    "\n",
    "    def _get_level_counters(self):\n",
    "        # stable order for nicer reports\n",
    "        ordered = [\"INFO\", \"WARN\", \"ERROR\", \"UNKNOWN\"]\n",
    "        pieces = []\n",
    "        for lvl in ordered:\n",
    "            if lvl in self.log_level_counters:\n",
    "                pieces.append(f\"{lvl} {self.log_level_counters[lvl]}\")\n",
    "\n",
    "        # include any unexpected levels (just in case)\n",
    "        for lvl, cnt in self.log_level_counters.items():\n",
    "            if lvl not in ordered:\n",
    "                pieces.append(f\"{lvl} {cnt}\")\n",
    "        return \"\\t\".join(pieces)\n",
    "\n",
    "    # ------------------------\n",
    "    # Logger extraction helpers\n",
    "    # ------------------------\n",
    "\n",
    "    def _extract_bracket_content(self, line: str) -> str:\n",
    "        \"\"\"\n",
    "        Extract the first [...] block from the line.\n",
    "        Returns \"\" if not found or malformed.\n",
    "        \"\"\"\n",
    "        start = line.find(\"[\")\n",
    "        if start == -1:\n",
    "            return \"\"\n",
    "        end = line.find(\"]\", start + 1)\n",
    "        if end == -1 or end <= start:\n",
    "            return \"\"\n",
    "        return line[start + 1 : end]\n",
    "\n",
    "    def sanitize_logger(self, logger: str) -> str:\n",
    "        \"\"\"\n",
    "        Your original sanitization was deleting separators and \"gluing\" tokens together.\n",
    "        That produced outputs like: 10.10.34.113888QuorumCnxManagerListener493\n",
    "\n",
    "        Instead, we keep a STABLE definition of \"logger/source\":\n",
    "          - take the bracket content (already extracted)\n",
    "          - keep only the part BEFORE the first ':' (common ZK pattern)\n",
    "            e.g. \"NIOServerCxn.Factory:0.0.0.0/...\" -> \"NIOServerCxn.Factory\"\n",
    "          - if empty/malformed -> UNKNOWN_SOURCE\n",
    "        \"\"\"\n",
    "        if not logger:\n",
    "            return \"UNKNOWN_SOURCE\"\n",
    "\n",
    "        # stable source name = left side before first ':'\n",
    "        stable = logger.split(\":\", 1)[0].strip()\n",
    "        if not stable:\n",
    "            return \"UNKNOWN_SOURCE\"\n",
    "\n",
    "        # light clean-up: keep readable chars, but DON'T glue meaningfully separated tokens\n",
    "        # (we allow dots, underscores, and hyphens too)\n",
    "        clean = []\n",
    "        for ch in stable:\n",
    "            if ch.isalnum() or ch in {\".\", \"_\", \"-\"}:\n",
    "                clean.append(ch)\n",
    "        stable_clean = \"\".join(clean).strip()\n",
    "\n",
    "        return stable_clean if stable_clean else \"UNKNOWN_SOURCE\"\n",
    "\n",
    "    def _count_loggers(self, logger: str):\n",
    "        clean_logger = self.sanitize_logger(logger)\n",
    "        self.loggers[clean_logger] = self.loggers.get(clean_logger, 0) + 1\n",
    "\n",
    "    def get_top_five_loggers(self):\n",
    "        \"\"\"\n",
    "        Your version returned the first 5 inserted, not the top 5 by count.\n",
    "        This one sorts by count descending.\n",
    "        \"\"\"\n",
    "        if not self.loggers:\n",
    "            return \"UNKNOWN_SOURCE 0\"\n",
    "\n",
    "        items = sorted(self.loggers.items(), key=lambda kv: kv[1], reverse=True)\n",
    "        top_five = items[:5]\n",
    "        return \"\\n\".join(f\"{name} {count}\" for name, count in top_five)\n",
    "\n",
    "    def get_file_report(self):\n",
    "        return f\"\"\"\n",
    "Log Level Counters:\\t{self._get_level_counters()}\n",
    "Total lines processed:\\t{self.total_lines_processed}\n",
    "Total Failed to process lines:\\t{self.parse_failed}\n",
    "Top 5 Loggers:\n",
    "{self.get_top_five_loggers()}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "deeda07b4f8cec88",
   "outputs": [],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T18:12:59.556661Z",
     "start_time": "2026-02-05T18:12:59.545945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---- pseudo main (jupyter-friendly) ----\n",
    "try:\n",
    "    log_processor = LogProcessor()\n",
    "\n",
    "    # keep your path style; adjust if needed in your notebook environment\n",
    "    zookeeper_logs = \"data/Zookeeper_2k.log\"\n",
    "\n",
    "    print(log_processor.inspect_log_file(zookeeper_logs))\n",
    "\n",
    "except OSError as error:\n",
    "    print(f\"Failed to Load file with error: {error}\")\n",
    "    sys.exit(2)\n"
   ],
   "id": "101489ac4abe608a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Log Level Counters:\tINFO 669\tWARN 1318\tERROR 13\n",
      "Total lines processed:\t2000\n",
      "Total Failed to process lines:\t0\n",
      "Top 5 Loggers:\n",
      "SendWorker 576\n",
      "RecvWorker 557\n",
      "NIOServerCxn.Factory 222\n",
      "QuorumPeermyid1 130\n",
      "10.10.34.13 106\n",
      "\n"
     ]
    }
   ],
   "execution_count": 134
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ---- pseudo main (CLI-friendly: read path from sys.argv[1]) ----\n",
    "try:\n",
    "    log_processor = LogProcessor()\n",
    "\n",
    "    # Validate user input\n",
    "    if len(sys.argv) != 2:\n",
    "        print(f\"Usage: {sys.argv[0]} <path_to_log_file>\")\n",
    "        sys.exit(2)\n",
    "\n",
    "    zookeeper_logs = sys.argv[1].strip()\n",
    "    if not zookeeper_logs:\n",
    "        print(\"Error: log file path is empty.\")\n",
    "        sys.exit(2)\n",
    "\n",
    "    # Run\n",
    "    report = log_processor.inspect_log_file(zookeeper_logs)\n",
    "    print(report)\n",
    "\n",
    "except FileNotFoundError as error:\n",
    "    print(f\"Error: {error}\")\n",
    "    sys.exit(2)\n",
    "\n",
    "except OSError as error:\n",
    "    print(f\"Failed to load file with error: {error}\")\n",
    "    sys.exit(2)\n"
   ],
   "id": "fa688cc13c048be4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
